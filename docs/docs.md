## Docs

### 擅长

1. 约束步骤。Step by Step，工程化的分析，给出足够多的上下文。
    - 信息没给够，不知道怎么做。
    - 缺少模型以外的信息。
2. 围绕一个软件的需求，能否给够相关信息。
3. 擅长的是：没有标准答案，总结、分类、提取信息，可以利用的原子能力。
    - 列出所有原能力（类似于微服务、背后能利用的能力）
4. Prompt as Code，Building Block 变了，作为基础能力
    - 例如，以前 A, B，C 能力。
5. 某些特定的就不擅长？
    - 传统工具：算法
    - MapReduce 的方式。
    - 函数式编程是不是更适合大语言模型。
6. 是不是所有应用和场景都能结合 LLM?
7. 检索增强：给模型提供的工具。
8. 原 AI 模型是不是真的高质量的语料
    - 代码是不是真的好，如何筛选
    - 代码质量还会不会很重要？
9. 让 AI 模型再作为人来进行监督。

### 1. 分析阶段：设计

如何分解 LLM，提取原子能力（总结、分类、提取信息），类似于微服务。我们需要基于约束好工程化步骤，结合我们的上下文，可以构建出更理想的 AI 应用。

在未来（LLM 上下文下），分析、设计软件的思路：解构需要解决的问题：

- 需要什么的基础 LLM 能力（Building Block：总结、分类、提取、翻译、逻辑推理）
- 哪些需要补充数据（上下文）
- 哪些需要插件/原始工具（Wolfram、日志分析）
- 哪些需要传统的算法。

### 2. 是不是所有应用和场景都能结合 LLM?

在不擅长的场景下：LLM 可以作为调度器。如实时性要求高的决策，网络相关的？（不一定通过 LLM 而是深度学习模型，如淘宝）。

函数式编程是不是更适合 LLM 的编程范式？ 如 MapReduce 方式的 LangChain。

其它场景下，诸如编码可以结合插件化的方式、CRUD 就擅长。代码是比较精确的、质量高的，容易验证。

### 3. 多模型架构

区分 AI 模型的能力，解决问题的领域能力，进行匹配。

1. AI 模型分工。不同的领域需要不同的模型知识。如大部分场景 GPT 是 OK 的，成本高慢，但是像 Copilot 采用的 Codex 速度快、结果好。
    - 优化的时候，低成本模型负责一部分的工作。
2. AI 相互监督。可以利用同一个模型，来强化问题解决。比如需求分析、写代码、测试，让几个 Prompt 让 AI 写，给出结果，然后人工选择。或者 Code Review。

